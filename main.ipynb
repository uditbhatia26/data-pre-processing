{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "<ul> Steps involved\n",
    "<li> Importing all the required libraries\n",
    "<li> Read Dataset\n",
    "<li> Duplicates and Garbage Value Treatment\n",
    "<li> Missing Value treatment\n",
    "<li> Normalisation\n",
    "<li> Outlier Treatment\n",
    "<li> Encoding\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Importing the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"salary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Removing irrelevant features and sorting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels=[\"fnlwgt\", \"education\", \"marital-status\", \"race\", \"relationship\", \"native-country\"], axis=1, inplace=True)\n",
    "data = data[[\"age\", \"education-num\", \"hours-per-week\", \"capital-gain\", \"capital-loss\", \"workclass\", \"occupation\", \"sex\", \"salary\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> The removal of 'native-country' was done as more than 75% of values were United-States and there was very less variability in that feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Removing all the duplicate values if present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated()\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> The data does not show any null values as all the null values have been replaced with '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Looking for Null and Garbage Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.select_dtypes(include=\"object\").columns:\n",
    "    print(data[i].value_counts())\n",
    "    print(\"***\"* 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> As we can see we have garbage values in the <b> 'workclass' </b>, <b>'occupation'</b> and <b>'native-country'</b> column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Replacing the '?' values with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(\" ?\" , np.nan, inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Removing Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Dropping null values from occupation and filling null values with mode in workclass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> If we drop the null values from occupation there are no more null values left in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in[\"occupation\"]:\n",
    "    data.dropna(inplace=True, subset=[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"workclass\"]:\n",
    "    data[i].fillna(data[i].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOX PLOT FOR OUTLIERS\n",
    "for i in ['age', 'education-num', 'hours-per-week']:\n",
    "    sns.boxplot(data=data, x  = i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"age\"]:\n",
    "    sns.pairplot(data=data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair plot for comparison\n",
    "for i in data.select_dtypes(include=\"number\").columns:\n",
    "    sns.pairplot(data=data, hue=i, y_vars=\"salary\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Plot\n",
    "# for i in [\"native-country\"]:\n",
    "#     plt.figure(figsize=(42,12))\n",
    "#     sns.barplot(data=data, x = i, y=\"occupation\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler #StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "data.iloc[:,0:5] = scaler.fit_transform(data.iloc[:,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Encoding the 'workclass', 'occupation', 'sex' and 'salary' columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Applying label encoding on sex and salary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for i in [\"sex\", \"salary\"]:\n",
    "    data[i] = le.fit_transform(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Applying one hot encoding on workclass and occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct = ColumnTransformer(transformers=[(\"encoder\", OneHotEncoder(), [3])], remainder = \"passthrough\")\n",
    "data = pd.DataFrame(ct.fit_transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers=[(\"encoder\", OneHotEncoder(), [10])], remainder = \"passthrough\")\n",
    "data = pd.DataFrame(ct.fit_transform(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wisker(col):\n",
    "    q1,q3 = np.percentile(col, [25,75])\n",
    "    iqr = q3 - q1\n",
    "    lw = q1 - (1.5 * iqr)\n",
    "    uw = q3 + (1.5 * iqr)\n",
    "    return lw, uw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['age', 'hours-per-week', 'education-num']:\n",
    "    lw,uw = wisker(data[i])\n",
    "    data[i] = np.where(data[i] < lw, lw, data[i])\n",
    "    data[i] = np.where(data[i] > uw, uw, data[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the cleaned dataset to a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"cleaned_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
